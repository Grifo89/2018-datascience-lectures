{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science â€“ Text Munging Exercises\n",
    "*COMP 5360 / MATH 4100, University of Utah, http://datasciencecourse.net/* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP\n",
    "\n",
    "### Exercise 1.1: Frequent Words\n",
    "Find the most frequently used words in Moby Dick which are not stopwords and not punctuation. Hint: [`str.isalpha()`](https://docs.python.org/3/library/stdtypes.html#str.isalpha) could be useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 19317 samples and 260819 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('whale', 906),\n",
       " ('one', 889),\n",
       " ('like', 624),\n",
       " ('upon', 538),\n",
       " ('man', 508),\n",
       " ('ship', 507),\n",
       " ('Ahab', 501),\n",
       " ('ye', 460),\n",
       " ('old', 436),\n",
       " ('sea', 433),\n",
       " ('would', 421),\n",
       " ('head', 335),\n",
       " ('though', 335),\n",
       " ('boat', 330),\n",
       " ('time', 324),\n",
       " ('long', 318),\n",
       " ('said', 302),\n",
       " ('yet', 300),\n",
       " ('still', 299),\n",
       " ('great', 293),\n",
       " ('two', 285),\n",
       " ('seemed', 283),\n",
       " ('must', 282),\n",
       " ('Whale', 282),\n",
       " ('last', 277),\n",
       " ('way', 269),\n",
       " ('Stubb', 255),\n",
       " ('see', 253),\n",
       " ('Queequeg', 252),\n",
       " ('little', 247),\n",
       " ('round', 242),\n",
       " ('whales', 237),\n",
       " ('say', 237),\n",
       " ('three', 237),\n",
       " ('men', 236),\n",
       " ('thou', 232),\n",
       " ('may', 230),\n",
       " ('us', 228),\n",
       " ('every', 222),\n",
       " ('much', 218),\n",
       " ('could', 215),\n",
       " ('Captain', 215),\n",
       " ('first', 210),\n",
       " ('side', 208),\n",
       " ('hand', 205),\n",
       " ('ever', 203),\n",
       " ('Starbuck', 196),\n",
       " ('never', 195),\n",
       " ('good', 192),\n",
       " ('white', 191)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_dist = FreqDist(text1)\n",
    "print(frequency_dist)\n",
    "\n",
    "most_common = frequency_dist.most_common(500)\n",
    "\n",
    "filtered_words = [word_tuple for word_tuple in most_common if word_tuple[0].lower() not in stopwords]\n",
    "filtered_words = [word_tuple for word_tuple in filtered_words if word_tuple[0].isalpha()]\n",
    "filtered_words[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.1\n",
    "\n",
    "You're an evil Spammer who's observed that many people try to obfuscate their e-mail using this notation: \"`alex at utah dot edu`\". Below are three examples of such e-mails text. Try to extract \"alex at utah dot edu\", etc. Start with the first string. Then extend your regular expression to work on all of them at the same time. Note that the second and third are slightly harder to do! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "html_smart = \"You can reach me: alex at utah dot edu\"\n",
    "html_smart2 = \"You can reach me: alex dot lex at utah dot edu\"\n",
    "html_smart3 = \"You can reach me: alex dot lex at sci dot utah dot edu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testRegex(regex):\n",
    "    for html in (html_smart, html_smart2, html_smart3):\n",
    "        print(re.search(regex, html).group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO write your regex here\n",
    "mail_regex = \"\\w+\\sat\\s\\w+\\sdot\\s\\w+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alex at utah dot edu\n",
      "lex at utah dot edu\n",
      "lex at sci dot utah\n"
     ]
    }
   ],
   "source": [
    "testRegex(mail_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alex at utah dot edu\n",
      "alex dot lex at utah dot edu\n",
      "alex dot lex at sci dot utah\n"
     ]
    }
   ],
   "source": [
    "better_regex = \"((\\w+\\s)+(\\sdot)*)+at\\s\\w+\\sdot\\s\\w+\"\n",
    "testRegex(better_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alex at utah dot edu\n",
      "alex dot lex at utah dot edu\n",
      "alex dot lex at sci dot utah dot edu\n"
     ]
    }
   ],
   "source": [
    "best_regex = \"((\\w+\\s)+(\\sdot)*)+at(\\s\\w+\\sdot)+\\s\\w+\"\n",
    "testRegex(best_regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.2: Find Adverbs\n",
    "\n",
    "Write a regular expression that finds all adverbs in a sentence. Adverbs are characterized by ending in \"ly\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"He was carefully disguised but captured quickly by police.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['carefully', 'quickly']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"\\w+ly\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.3: Phone Numbers\n",
    "\n",
    "Extract the phone numbers that follow a (xxx) xxx-xxxx pattern from the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phone_numbers = \"(857) 131-2235, (801) 134-2215, but this one (12) 13044441 shouldnt match. Also, this is common in twelve (12) countries and one (1) state\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(857) 131-2235', '(801) 134-2215']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"\\([0-9]{3}\\)\\s[0-9]{3}-[0-9]{4}\", phone_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.4: HTML Content\n",
    "\n",
    "Extract the content between the `<b>` and `<i>` tags but not the other tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html_tags = \"This is <b>important</b> and <u>very</u><i>timely</i>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['important', 'timely']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"<[bi]>(.*?)<\\/[bi]>\", html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
